{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Импорт модулей\n"
      ],
      "metadata": {
        "id": "QHDxUR631obi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import logging\n",
        "from typing import Optional\n",
        "\n",
        "logger = logging.getLogger(\"my_transformer\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ZfUlYgaQlU5a"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding"
      ],
      "metadata": {
        "id": "cNOUN78UAd9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формулы для расчета:\n",
        "$$PE_(pos, 2i) = sin(\\frac{pos}{10000^{2i/d_{model}}})$$\n",
        "$$PE_(pos, 2i+1) = cos(\\frac{pos}{10000^{2i/d_{model}}})$$"
      ],
      "metadata": {
        "id": "rCIBOy1DAgth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(max_len: int, d_model: int):\n",
        "    denom = torch.pow(torch.tensor(10_000.0), torch.arange(0, d_model, 2) / d_model)\n",
        "    pos_encoding = torch.arange(max_len, dtype=torch.float32).unsqueeze(1).repeat(1, d_model)\n",
        "\n",
        "    pos_encoding[:, 0::2] = torch.sin(pos_encoding[:, 0::2] / denom)\n",
        "    pos_encoding[:, 1::2] = torch.cos(pos_encoding[:, 1::2] / denom)\n",
        "\n",
        "    return pos_encoding"
      ],
      "metadata": {
        "id": "434R4mLC9qve"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding(10, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aNHJ4wGBSM4",
        "outputId": "b8554728-92a3-4bc1-e487-3487d9c44462"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
              "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
              "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
              "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
              "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
              "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
              "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
              "          9.9955e-01,  3.0000e-03,  1.0000e+00],\n",
              "        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n",
              "          9.9920e-01,  4.0000e-03,  9.9999e-01],\n",
              "        [-9.5892e-01,  2.8366e-01,  4.7943e-01,  8.7758e-01,  4.9979e-02,\n",
              "          9.9875e-01,  5.0000e-03,  9.9999e-01],\n",
              "        [-2.7942e-01,  9.6017e-01,  5.6464e-01,  8.2534e-01,  5.9964e-02,\n",
              "          9.9820e-01,  6.0000e-03,  9.9998e-01],\n",
              "        [ 6.5699e-01,  7.5390e-01,  6.4422e-01,  7.6484e-01,  6.9943e-02,\n",
              "          9.9755e-01,  6.9999e-03,  9.9998e-01],\n",
              "        [ 9.8936e-01, -1.4550e-01,  7.1736e-01,  6.9671e-01,  7.9915e-02,\n",
              "          9.9680e-01,  7.9999e-03,  9.9997e-01],\n",
              "        [ 4.1212e-01, -9.1113e-01,  7.8333e-01,  6.2161e-01,  8.9879e-02,\n",
              "          9.9595e-01,  8.9999e-03,  9.9996e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention"
      ],
      "metadata": {
        "id": "CXNd947bEsKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$Attention(K, Q, V) = softmax(\\frac{QK^T}{\\sqrt(d_k)})V$$"
      ],
      "metadata": {
        "id": "z_SRYub7Evx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(\n",
        "    Q: torch.tensor,\n",
        "    K: torch.tensor,\n",
        "    V: torch.tensor,\n",
        "    dropout: Optional[nn.Dropout] = None,\n",
        "    mask: Optional[torch.tensor] = None\n",
        ") -> tuple[torch.tensor, Optional[torch.tensor]]:\n",
        "    \"\"\"\n",
        "    Считаем внимание\n",
        "    Размеры тензоров:\n",
        "    - Q [batch_size, m, d_model]\n",
        "    - K [batch_size, m, d_model]\n",
        "    - V [batch_size, m, d_model]\n",
        "    \"\"\"\n",
        "    d_k = K.size(-1)\n",
        "    scale = torch.sqrt(torch.tensor(d_k)).to(device)\n",
        "    attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / scale\n",
        "\n",
        "    if mask is not None:\n",
        "        attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "    attention_weights = F.softmax(attention_scores, dim = -1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        attentions_weights = dropout(attentions_weights)\n",
        "\n",
        "    values = torch.matmul(attention_weights, V)\n",
        "\n",
        "    return values, attention_weights\n"
      ],
      "metadata": {
        "id": "pgeTHUkUIhzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_heads(m_tensor: torch.tensor, num_heads: int):\n",
        "    batch_size, max_len, d_model = m_tensor.size()\n",
        "    head_dim = d_model // num_heads\n",
        "\n",
        "    m_tensor = m_tensor.view(batch_size, max_len, num_heads, head_dim)\n",
        "\n",
        "    m_tensor.transpose(1, 2)\n",
        "\n",
        "    return m_tensor"
      ],
      "metadata": {
        "id": "l2SDKeVkPWm0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itH63xF6QLk3",
        "outputId": "c2b1088b-554d-4ade-f5c4-e96b92f4ac87"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1, 2],\n",
              "          [3, 4]],\n",
              "\n",
              "         [[5, 6],\n",
              "          [7, 8]],\n",
              "\n",
              "         [[1, 2],\n",
              "          [3, 4]],\n",
              "\n",
              "         [[5, 6],\n",
              "          [7, 8]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, num_heads: int, dropout: float = 0.1):\n",
        "      super(MultiHeadAttention, self).__init__()\n",
        "      self.num_heads = num_heads\n",
        "      self.head_dim = d_model // num_heads\n",
        "\n",
        "      self.W_k = nn.Linear(d_model, d_model, bias = False)\n",
        "      self.W_q = nn.Linear(d_model, d_model, bias = False)\n",
        "      self.W_v = nn.Linear(d_model, d_model, bias = False)\n",
        "\n",
        "      self.W_o = nn.Linear(d_model, d_model, bias = False)\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, Q: torch.tensor,\n",
        "                K: torch.tensor, V: torch.tensor,\n",
        "                mask: Optional[torch.tensor] = None):\n",
        "      Q = self.W_q(Q)\n",
        "      K = self.W_k(K)\n",
        "      V = self.W_v(V)\n",
        "      batch_size = Q.size(0)\n",
        "      d_model = Q.size(-1)\n",
        "\n",
        "      # TODO добавить маску!\n",
        "      Q = split_heads(Q, self.num_heads)\n",
        "      K = split_heads(K, self.num_heads)\n",
        "      V = split_heads(V, self.num_heads)\n",
        "\n",
        "      output, attention_weights = attention(Q, K, V, dropout = self.dropout, mask = self.mask)\n",
        "      output = output.permute(0, 2, 1, 3).reshape(batch_size, -1, d_model)\n",
        "      output = self.W_o(output)\n",
        "\n",
        "      return output, attention_weights\n"
      ],
      "metadata": {
        "id": "JnnyfoAxMUgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LayerNorm"
      ],
      "metadata": {
        "id": "VMBqjszuRS7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model: int, eps: float = 1e-5):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.eps = eps\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
        "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
        "\n",
        "    def forward(self, x: torch.tensor) -> torch.float:\n",
        "        mean = x.mean()\n",
        "        std = x.std()\n",
        "\n",
        "        x_normalized = self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "        return x_normalized"
      ],
      "metadata": {
        "id": "I4MoQoODRLf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FFN"
      ],
      "metadata": {
        "id": "pI1RLik_Srcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, d_model: int, d_out: int, dropout: float = 0.1):\n",
        "        super(FFN, self).__init__()\n",
        "        self.W_1 = nn.Linear(d_model, d_out)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.W_2 = nn.Linear(d_out, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x:torch.tensor):\n",
        "      output = self.W_1(x)\n",
        "      output = self.dropout(self.relu(output))\n",
        "      output = self.W_2(output)\n",
        "\n",
        "      return output"
      ],
      "metadata": {
        "id": "L5Zz8-W2Stm0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Полезные ссылки:\n",
        "\n",
        "* [\"*On Layer Normalization in the Transformer Architecture*\"](https://arxiv.org/pdf/2002.04745.pdf)\n",
        "* [\"*Attention is all you Need*\"](https://ailab-ua.github.io/courses/resources/Attention_Vaswani_2017.pdf)\n",
        "* [\"*Illustrated transformer by J.Allamar*\"](https://jalammar.github.io/illustrated-transformer/)"
      ],
      "metadata": {
        "id": "cQSoJZLd9rLo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4DLL5b095fD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}